---
title: "Competición Minería de datos: preprocesamiento y clasificación"
author: "Wenceslao Arroyo Machado"
date: "4/2/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(dummies)
```


## Carga de datos

```{r}
Train <- read.csv2("my_dataset_train.csv", sep=",", dec=".", stringsAsFactors = FALSE)
Test <- read.csv2("my_dataset_test.csv", sep=",", dec=".", stringsAsFactors = FALSE)

summary(Train)
summary(Test)
```

## Estudio de valores perdidos en Train
No hay instancias con más de un valor perdido, la variable que más tiene son 8.
```{r}
perdidosTrain <- valoresPerdidos(Train)
plot(perdidosTrain$`Total de perdidos por variable`)
```

## Estudio de valores perdidos en Test
No hay instancias con más de un valor perdido, la variable que más tiene son 8.
```{r}
perdidosTest <- valoresPerdidos(Test)
plot(perdidosTest$`Total de perdidos por variable`)
```

### Comparativa de valores perdidos entre Train y Test
Busco aquellas variables de Test que menos valores perdidos tienen, las que no tienen alguno ya las cojo despues, y que a su vez en Train también menos tienen.
```{r}
diferenciasValoresPerdidos <- abs(variablesPerdidosTr[-76]-variablesPerdidosTs)
indiceDiferenciasMinimas <- which(diferenciasValoresPerdidos<2 & variablesPerdidosTs<2 & variablesPerdidosTs>0)
variablesPerdidosTs[indiceDiferenciasMinimas] #x3, x18, x51, x60, x72 

library(ggplot2)
ggplot()+
  geom_col(aes(1:75,variablesPerdidosTr[-76]),alpha=.8,fill='pink',color='red')+
  geom_col(aes(1:75,variablesPerdidosTs),alpha=.3,fill='lightblue',color='lightblue4')
```

## Imputación valores

```{r}
summary(Train[,c("x3", "x18","x51", "x60", "x72")])
head(Train[,c("x3", "x18","x51", "x60", "x72")])
summary(factor(Train[,"x51"]))

library(mice)
?mice
mice(Train[,c("x3", "x18","x51", "x60", "x72")])
```

## Estudio de variables categóricas

```{r}
# Variables categóricas
head(Train[,c("x0", "x14", "x17", "x51", "x61", "x63")])
summary(factor(Train$x0))
which(Train$x0=="") #[1] 1200 1497 1500 1625 2039
summary(factor(Train$x14))
which(Train$x14=="") #[1]  711 1830 1979 2199 2229
summary(factor(Train$x17))
which(Train$x17=="") #[1]   78  671 1076 2289
summary(factor(Train$x51))
which(Train$x51=="") #[1]  513 2470
summary(factor(Train$x61))
which(Train$x61=="") #[1]  606 1334 1608
summary(factor(Train$x63))
which(Train$x63=="") #[1]  872 1064 1613 2166 2258
```


# Prueba inicial con todas las variables posibles
Hay variables con NAs y campos vacios ("") en Test, por lo que para la primera prueba no me complico y selecciono las variables que en Test no tienen ninguno de ellos.
```{r}
# Me quedo con las varaibles que no tienen NAs o campos vacios (""), tanto para Train como Test, en base a las de estas últimas
test <- Test[,-perdidosTest$`Varaibles con perdidos`]
train <- Train[,-perdidosTest$`Varaibles con perdidos`]

# Me quedo solo con las instancias sin perdidos para esas variables y quito la clase
train <- train[-perdidosTrain$`Instancias con perdidos`,-31]

# Asigno a una nueva variable dichas clases
train.class <- Train[-perdidosTrain$`Instancias con perdidos`,76]
```

# Modelos
Hago dos modelos con 1-NN y GLM sin hacer uso de dos variables que son categóricas.
```{r}
# 1-NN 
modelo <- train(train[,-c(7,27)], train.class,
                method = "knn",
                preProcess = c("center","scale"),
                tuneGrid = data.frame(.k=1),
                tuneLength = 10,
                trControl = trainControl(method = "cv"))
modelo.predict <- predict(modelo,test[,-c(7,27)])

# GLM
modelo <- train(train[,-c(7,27)], train.class,
                method = "glm",
                preProcess = c("center","scale"),
                tuneLength = 10,
                trControl = trainControl(method = "cv"))
modelo.predict <- predict(modelo,test[,-c(7,27)])

# En el caso de GLM se hace un redondeo
predicciones <- round(modelo.predict, 0)

# Construyo la matriz de predicciones
predicciones <- matrix(c(1:683,predicciones),683,2,byrow = FALSE)
colnames(predicciones) <- c("Id","Prediction")
# Guardo
write.table(predicciones, "sample.csv", col.names = TRUE, row.names = FALSE,
            quote=FALSE, sep = ",")
```

## Prueba imputacion medias (numericos)
```{r}
# Hago una copia de train y test para no alterar las originales
training <- imputacionCaracteres(Train)
testing <- imputacionCaracteres(Test)

# Quito las categoricas y la clase, en training
training <- training[,-c(1, 15, 18, 52, 62, 64, 76)]
testing <- testing[,-c(1, 15, 18, 52, 62, 64)]

# Normalizo train y test
training <- data.frame(scale(training))
testing <- data.frame(scale(testing))

# Creo las clases
train.class <- Train[,76]
train.class0 <- as.integer(I(train.class==0))
train.class1 <- as.integer(I(train.class==1))
train.class2 <- as.integer(I(train.class==2))
train.class3 <- as.integer(I(train.class==3))

# Dataframes
training0 <- cbind(training, y=train.class0)
training1 <- cbind(training, y=train.class1)
training2 <- cbind(training, y=train.class2)
training3 <- cbind(training, y=train.class3)

# Modelos y predicciones
modelo0 <- glm(y~., data=training0)
modelo.predict0 <- predict(modelo0,newdata=testing ,type="response")
modelo1 <- glm(y~., data=training1)
modelo.predict1 <- predict(modelo1,newdata=testing ,type="response")
modelo2 <- glm(y~., data=training2)
modelo.predict2 <- predict(modelo2,newdata=testing ,type="response")
modelo3 <- glm(y~., data=training3)
modelo.predict3 <- predict(modelo3,newdata=testing ,type="response")

# Predicciones
predicciones <- ifelse(modelo.predict0>modelo.predict1 & modelo.predict0>modelo.predict2 & modelo.predict0>modelo.predict3, 0,
       ifelse(modelo.predict1>modelo.predict2 & modelo.predict1>modelo.predict3, 1,
              ifelse(modelo.predict2>modelo.predict3, 2, 3) ))
summary(factor(predicciones))

# Construyo la matriz de predicciones
predicciones <- matrix(c(1:683,predicciones),683,2,byrow = FALSE)
colnames(predicciones) <- c("Id","Prediction")
# Guardo
write.table(predicciones, "sample.csv", col.names = TRUE, row.names = FALSE,
            quote=FALSE, sep = ",")
```

## Prueba imputacion medias (numericos) y moda (categóricos) convertidos en dummies
```{r}
# Hago una copia de train y test para no alterar las originales
training <- imputacionNumericos(Train)
testing <- imputacionNumericos(Test)

# Quito las categoricas y la clase, en training
training <- imputacionCaracteres(training)
testing <- imputacionCaracteres(testing)

# Quito la clase
training <- training[,-76]

# Dummies
training[,15] <- as.integer(I(training[,15])=="true")
training[,52] <- as.integer(I(training[,52])=="yes")
training[,64] <- as.integer(I(training[,64])=="active")
training<-cbind(training[,-1],data.frame(dummy(training[,1]))[-1])
#Importante asignar los mismos nombre a training y test
names(training)[75:78]<-c("x75","x76","x77", "x78")

testing[,15] <- as.integer(I(testing[,15])=="true")
testing[,52] <- as.integer(I(testing[,52])=="yes")
testing[,64] <- as.integer(I(testing[,64])=="active")
testing<-cbind(testing[,-1],data.frame(dummy(testing[,1]))[-1])
names(testing)[75:78]<-c("x75","x76","x77", "x78")

training <- training[,-c(17,61)]
testing <- testing[,-c(17,61)]


# Normalizo train y test
training <- data.frame(scale(training))
testing <- data.frame(scale(testing))

# Creo las clases
train.class <- Train[,76]
train.class0 <- as.integer(I(train.class==0))
train.class1 <- as.integer(I(train.class==1))
train.class2 <- as.integer(I(train.class==2))
train.class3 <- as.integer(I(train.class==3))

# Dataframes
training0 <- cbind(training, y=train.class0)
training1 <- cbind(training, y=train.class1)
training2 <- cbind(training, y=train.class2)
training3 <- cbind(training, y=train.class3)

# Modelos y predicciones
modelo0 <- glm(y~., data=training0)
modelo.predict0 <- predict(modelo0,newdata=testing ,type="response")
modelo1 <- glm(y~., data=training1)
modelo.predict1 <- predict(modelo1,newdata=testing ,type="response")
modelo2 <- glm(y~., data=training2)
modelo.predict2 <- predict(modelo2,newdata=testing ,type="response")
modelo3 <- glm(y~., data=training3)
modelo.predict3 <- predict(modelo3,newdata=testing ,type="response")

# Predicciones
predicciones <- ifelse(modelo.predict0>modelo.predict1 & modelo.predict0>modelo.predict2 & modelo.predict0>modelo.predict3, 0,
       ifelse(modelo.predict1>modelo.predict2 & modelo.predict1>modelo.predict3, 1,
              ifelse(modelo.predict2>modelo.predict3, 2, 3) ))
summary(factor(predicciones))

# Construyo la matriz de predicciones
predicciones <- matrix(c(1:683,predicciones),683,2,byrow = FALSE)
colnames(predicciones) <- c("Id","Prediction")
# Guardo
write.table(predicciones, "sample.csv", col.names = TRUE, row.names = FALSE,
            quote=FALSE, sep = ",")
```

```{r}

# Hago una copia de train y test para no alterar las originales
training <- train
testing <- test

# Transformo de las copias de train y test los categóricos en numéricos
training[,7]<-ifelse(training[,7]=="true",1,0)
training[,27]<-ifelse(training[,27]=="active",1,0)
testing[,7]<-ifelse(testing[,7]=="true",1,0)
testing[,27]<-ifelse(testing[,27]=="active",1,0)


# Normalizo train y test
training <- data.frame(scale(training))
testing <- data.frame(scale(testing))

# Creo las clases
train.class0 <- as.integer(I(train.class==0))
train.class1 <- as.integer(I(train.class==1))
train.class2 <- as.integer(I(train.class==2))
train.class3 <- as.integer(I(train.class==3))

# Dataframes
training0 <- cbind(training, y=train.class0)
training1 <- cbind(training, y=train.class1)
training2 <- cbind(training, y=train.class2)
training3 <- cbind(training, y=train.class3)

# Modelos y predicciones
modelo0 <- glm(y~., data=training0)
modelo.predict0 <- predict(modelo0,newdata=testing ,type="response")
modelo1 <- glm(y~., data=training1)
modelo.predict1 <- predict(modelo1,newdata=testing ,type="response")
modelo2 <- glm(y~., data=training2)
modelo.predict2 <- predict(modelo2,newdata=testing ,type="response")
modelo3 <- glm(y~., data=training3)
modelo.predict3 <- predict(modelo3,newdata=testing ,type="response")

# Dataframe con predicciones
dataPredicciones <- data.frame("0"=modelo.predict0, "1"=modelo.predict1, "2"=modelo.predict2, "3"=modelo.predict3)
# Dataframe con predicciones redondeadas
dataPrediccionesRound <- round(dataPredicciones)

# Selección de la clase en base a la mayor predicción
predicciones <- ifelse(modelo.predict0>modelo.predict1 & modelo.predict0>modelo.predict2 & modelo.predict0>modelo.predict3, 0,
       ifelse(modelo.predict1>modelo.predict2 & modelo.predict1>modelo.predict3, 1,
              ifelse(modelo.predict2>modelo.predict3, 2, 3) ))
summary(factor(predicciones))

# Construyo la matriz de predicciones
predicciones <- matrix(c(1:683,predicciones),683,2,byrow = FALSE)
colnames(predicciones) <- c("Id","Prediction")
# Guardo
write.table(predicciones, "sample.csv", col.names = TRUE, row.names = FALSE,
            quote=FALSE, sep = ",")
```