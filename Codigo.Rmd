---
title: "Competición Minería de datos: preprocesamiento y clasificación"
author: "Wenceslao Arroyo Machado"
date: "4/2/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Función propia para obtener la moda
moda <- function(x) {
  t <- table(x)
  return(as.numeric(names(t)[t == max(t)]))
  
}
library(caret)
```


## Carga de datos

```{r}
Train <- read.csv2("my_dataset_train.csv", sep=",", dec=".", stringsAsFactors = FALSE)
Test <- read.csv2("my_dataset_test.csv", sep=",", dec=".", stringsAsFactors = FALSE)

summary(Train)
summary(Test)
```

## Estudio de valores perdidos en Train
No hay instancias con más de un valor perdido, la variable que más tiene son 8.
```{r}
instanciasPerdidosTr <- sapply(1:dim(Train)[1], function(x) sum(is.na(Train[x,]))+sum(Train[x,]=="", na.rm = TRUE))
max(instanciasPerdidosTr) # No hay más de un valor perdido por instancia
sum(instanciasPerdidosTr) # Hay 269 instancias con valores perdidos
variablesPerdidosTr <- sapply(1:dim(Train)[2], function(x) sum(is.na(Train[,x]))+sum(Train[,x]=="", na.rm = TRUE))
max(variablesPerdidosTr) # La variable con más perdidos tiene 8
names(variablesPerdidosTr) <- colnames(Train)
variablesPerdidosTr
plot(variablesPerdidosTr)
```

## Estudio de valores perdidos en Test
No hay instancias con más de un valor perdido, la variable que más tiene son 8.
```{r}
instanciasPerdidosTs <- sapply(1:dim(Test)[1], function(x) sum(is.na(Test[x,]))+sum(Test[x,]=="", na.rm = TRUE))
max(instanciasPerdidosTs) # No hay más de un valor perdido por instancia
sum(instanciasPerdidosTs) # Hay 72 instancias con valores perdidos
variablesPerdidosTs <- sapply(1:dim(Test)[2], function(x) sum(is.na(Test[,x]))+sum(Test[,x]=="", na.rm = TRUE))
max(variablesPerdidosTs) # La variable con más perdidos tiene 5
names(variablesPerdidosTs) <- colnames(Test)
variablesPerdidosTs
plot(variablesPerdidosTs)
```

### Comparativa de valores perdidos entre Train y Test
Busco aquellas variables de Test que menos valores perdidos tienen, las que no tienen alguno ya las cojo despues, y que a su vez en Train también menos tienen.
```{r}
diferenciasValoresPerdidos <- abs(variablesPerdidosTr[-76]-variablesPerdidosTs)
indiceDiferenciasMinimas <- which(diferenciasValoresPerdidos<2 & variablesPerdidosTs<2 & variablesPerdidosTs>0)
variablesPerdidosTs[indiceDiferenciasMinimas] #x3, x18, x51, x60, x72 

library(ggplot2)
ggplot()+
  geom_col(aes(1:75,variablesPerdidosTr[-76]),alpha=.8,fill='pink',color='red')+
  geom_col(aes(1:75,variablesPerdidosTs),alpha=.3,fill='lightblue',color='lightblue4')
```

## Imputación valores

```{r}
summary(Train[,c("x3", "x18","x51", "x60", "x72")])
head(Train[,c("x3", "x18","x51", "x60", "x72")])
summary(factor(Train[,"x51"]))

library(mice)
?mice
mice(Train[,c("x3", "x18","x51", "x60", "x72")])
```

## Estudio de variables categóricas

```{r}
# Variables categóricas
head(Train[,c("x0", "x14", "x17", "x51", "x61", "x63")])
summary(factor(Train$x0))
which(Train$x0=="") #[1] 1200 1497 1500 1625 2039
summary(factor(Train$x14))
which(Train$x14=="") #[1]  711 1830 1979 2199 2229
summary(factor(Train$x17))
which(Train$x17=="") #[1]   78  671 1076 2289
summary(factor(Train$x51))
which(Train$x51=="") #[1]  513 2470
summary(factor(Train$x61))
which(Train$x61=="") #[1]  606 1334 1608
summary(factor(Train$x63))
which(Train$x63=="") #[1]  872 1064 1613 2166 2258
```


# Prueba inicial con todas las variables posibles
Hay variables con NAs y campos vacios ("") en Test, por lo que para la primera prueba no me complico y selecciono las variables que en Test no tienen ninguno de ellos.
```{r}
# Variables test problemáticas en Test
variablesNA <- sapply(1:75, function(x) any(is.na(Test[,x]) | Test[,x]==""))
variablesNA <- which(!variablesNA)
# Me quedo con las varaibles que no tienen NAs o campos vacios (""), tanto para Train como Test, en base a las de estas últimas
test <- Test[,variablesNA]
train <- Train[,variablesNA]

# Selecciono a su vez las instancias sin NAs o campos vacios ("") de Train
instannciasNA <- sapply(1:dim(train)[1], function(x) any(is.na(train[x,]) | train[x,]==""))
instannciasNA <- which(!instannciasNA)
train <- train[instannciasNA,]
# Me quedo con las clases de esas instancias
train.class <- Train[instannciasNA,76]
```

# Modelos
Hago dos modelos con 1-NN y GLM sin hacer uso de dos variables que son categóricas.
```{r}
# 1-NN 
modelo <- train(train[,-c(7,27)], train.class,
                method = "knn",
                preProcess = c("center","scale"),
                tuneGrid = data.frame(.k=1),
                tuneLength = 10,
                trControl = trainControl(method = "cv"))
modelo.predict <- predict(modelo,test[,-c(7,27)])

# GLM
modelo <- train(train[,-c(7,27)], train.class,
                method = "glm",
                preProcess = c("center","scale"),
                tuneLength = 10,
                trControl = trainControl(method = "cv"))
modelo.predict <- predict(modelo,test[,-c(7,27)])

# En el caso de GLM se hace un redondeo
predicciones <- round(modelo.predict, 0)

# Construyo la matriz de predicciones
predicciones <- matrix(c(1:683,predicciones),683,2,byrow = FALSE)
colnames(predicciones) <- c("Id","Prediction")
# Guardo
write.table(predicciones, "sample.csv", col.names = TRUE, row.names = FALSE,
            quote=FALSE, sep = ",")
```

```{r}

# Hago una copia de train y test para no alterar las originales
training <- train
testing <- test

# Transformo de las copias de train y test los categóricos en numéricos
training[,7]<-ifelse(training[,7]=="true",1,0)
training[,27]<-ifelse(training[,27]=="active",1,0)
testing[,7]<-ifelse(testing[,7]=="true",1,0)
testing[,27]<-ifelse(testing[,27]=="active",1,0)


# Normalizo train y test
training <- data.frame(scale(training))
testing <- data.frame(scale(testing))


# Dataframes
training0 <- cbind(training, y=train.class0)
training1 <- cbind(training, y=train.class1)
training2 <- cbind(training, y=train.class2)
training3 <- cbind(training, y=train.class3)

# Modelos y predicciones
modelo0 <- glm(y~., data=training0)
modelo.predict0 <- predict(modelo0,newdata=testing ,type="response")
modelo1 <- glm(y~., data=training1)
modelo.predict1 <- predict(modelo1,newdata=testing ,type="response")
modelo2 <- glm(y~., data=training2)
modelo.predict2 <- predict(modelo2,newdata=testing ,type="response")
modelo3 <- glm(y~., data=training3)
modelo.predict3 <- predict(modelo3,newdata=testing ,type="response")

# Dataframe con predicciones
dataPredicciones <- data.frame("0"=modelo.predict0, "1"=modelo.predict1, "2"=modelo.predict2, "3"=modelo.predict3)
# Dataframe con predicciones redondeadas
dataPrediccionesRound <- round(dataPredicciones)

# Selección de la clase en base a la mayor predicción
predicciones <- ifelse(modelo.predict0>modelo.predict1 & modelo.predict0>modelo.predict2 & modelo.predict0>modelo.predict3, 0,
       ifelse(modelo.predict1>modelo.predict2 & modelo.predict1>modelo.predict3, 1,
              ifelse(modelo.predict2>modelo.predict3, 2, 3) ))
summary(factor(predicciones))

# Construyo la matriz de predicciones
predicciones <- matrix(c(1:683,predicciones),683,2,byrow = FALSE)
colnames(predicciones) <- c("Id","Prediction")
# Guardo
write.table(predicciones, "sample.csv", col.names = TRUE, row.names = FALSE,
            quote=FALSE, sep = ",")
```